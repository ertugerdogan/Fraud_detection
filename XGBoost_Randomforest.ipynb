{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_item_count = 24\n",
    "rarity_thershold = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/g5v5834n5mgg95k1hkl9_yc40000gn/T/ipykernel_4585/896890968.py:4: DtypeWarning: Columns (11,12,13,14,15,16,17,18,19,20,21,22,23,24,59,60,61,62,63,64,65,66,67,68,69,70,71,72,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,102,103,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(csv_file_path_train)\n",
      "/var/folders/6h/g5v5834n5mgg95k1hkl9_yc40000gn/T/ipykernel_4585/896890968.py:5: DtypeWarning: Columns (97,105,107,108,109,110,111,112,113,114,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_test = pd.read_csv(csv_file_path_test)\n"
     ]
    }
   ],
   "source": [
    "csv_file_path_train = './train_dataset.csv'\n",
    "csv_file_path_test = './submission_data_x.csv'\n",
    "\n",
    "df_train = pd.read_csv(csv_file_path_train)\n",
    "df_test = pd.read_csv(csv_file_path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6h/g5v5834n5mgg95k1hkl9_yc40000gn/T/ipykernel_4585/222863778.py:1: DtypeWarning: Columns (11,12,13,14,15,16,17,18,19,20,21,22,23,24,59,60,61,62,63,64,65,66,67,68,69,70,71,72,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,102,103,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_train = pd.read_csv(csv_file_path_train)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(csv_file_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the TEST data\n",
    "col_list = [\"item\", \"make\", \"model\", \"goods_code\"]\n",
    "all_colmns_to_append = []\n",
    "for clmn_name in col_list:\n",
    "\n",
    "    # Extract uniqueness and repetiteveness\n",
    "    row_count = df_test.shape[0]\n",
    "    count_dict = defaultdict(int)\n",
    "    \n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "\n",
    "    for col in cols:\n",
    "        column_values = df_test[col]\n",
    "        # del df_test[col]\n",
    "        for row in range(row_count - 1):\n",
    "            item = column_values[row]\n",
    "            if pd.notna(item):\n",
    "                count_dict[str(item)] += 1\n",
    "\n",
    "    count_dict = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # ADD COLUMNS  \n",
    "    for key, count in count_dict:\n",
    "        if count > rarity_thershold:\n",
    "            all_colmns_to_append.append(str(key))\n",
    "\n",
    "all_colmns_to_append = list(set(all_colmns_to_append))\n",
    "new_data = pd.DataFrame(0, index=df_test.index, columns=all_colmns_to_append)\n",
    "df_test = pd.concat([df_test, new_data], axis=1)\n",
    "\n",
    "for clmn_name in col_list:\n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "    # FILL NEWLY ADDED COLUMNS\n",
    "    for index, row in df_test.iterrows():\n",
    "        for col in cols:\n",
    "            cell = row[col]\n",
    "            if not pd.notna(cell):\n",
    "                break\n",
    "            if cell in df_test.columns:\n",
    "                df_test.at[index, cell] = 1\n",
    "\n",
    "    # DROP OLD COLUMNS\n",
    "    for col in cols:\n",
    "        del df_test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage the TRAIN data\n",
    "\n",
    "# ADD COLUMNS\n",
    "cols_df_test = list(df_test.columns)\n",
    "cols_df_train = list(df_train.columns)\n",
    "cols_add_train = []\n",
    "\n",
    "for col in cols_df_test:\n",
    "    if col not in cols_df_train:\n",
    "        cols_add_train.append(col)\n",
    "\n",
    "new_data = pd.DataFrame(0, index=df_train.index, columns=cols_add_train)\n",
    "df_train = pd.concat([df_train, new_data], axis=1)\n",
    "\n",
    "for clmn_name in col_list:\n",
    "\n",
    "    cols = {clmn_name+str(i) for i in range(1,max_item_count+1)}\n",
    "\n",
    "    # # FILL NEWLY ADDED COLUMNS\n",
    "    for index, row in df_train.iterrows():\n",
    "        for col in cols:\n",
    "            cell = row[col]\n",
    "            if not pd.notna(cell):\n",
    "                break\n",
    "            if cell in df_train.columns:\n",
    "                df_train.at[index, cell] = 1\n",
    "\n",
    "    # DROP OLD COLUMNS\n",
    "    for col in cols:\n",
    "        del df_train[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(0)\n",
    "\n",
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "Probabilities: [0.24 0.01 0.   ... 0.   0.   0.  ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "train_y = df_train['fraud_flag']  \n",
    "train_x = df_train.drop(columns=['fraud_flag'])  \n",
    "\n",
    "\n",
    "model = RandomForestClassifier()  \n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "predictions = model.predict(df_test)\n",
    "probabilities = model.predict_proba(df_test)[:, 1]  \n",
    "\n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Probabilities:\", probabilities)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 0 0 ... 0 0 0]\n",
      "Probabilities: [0.00075525 0.00607294 0.00742015 ... 0.00166458 0.00741968 0.00547982]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "train_y = df_train['fraud_flag']\n",
    "train_x = df_train.drop(columns=['fraud_flag'])\n",
    "\n",
    "\n",
    "model = XGBClassifier() \n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "predictions = model.predict(df_test)\n",
    "probabilities = model.predict_proba(df_test)[:, 1] \n",
    "\n",
    "print(\"Predictions:\", predictions)\n",
    "print(\"Probabilities:\", probabilities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "train_y = df_train['fraud_flag']\n",
    "train_x = df_train.drop(columns=['fraud_flag'])\n",
    "\n",
    "X_train, X_new_test, y_train, y_new_test = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Average Precision Score: 0.19270252343162442\n",
      "XGBoost Average Precision Score: 0.21311064481889538\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_new_test_probabilities = rf_model.predict_proba(X_new_test)[:, 1]\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_new_test_probabilities = xgb_model.predict_proba(X_new_test)[:, 1]\n",
    "\n",
    "results_df = pd.DataFrame({'Actual': y_new_test, \n",
    "                           'RF_Predicted_Probability': rf_new_test_probabilities,\n",
    "                           'XGB_Predicted_Probability': xgb_new_test_probabilities})\n",
    "\n",
    "results_df.to_csv('new_test_results.txt', index=False, sep='\\t')\n",
    "\n",
    "rf_average_precision = average_precision_score(results_df['Actual'], results_df['RF_Predicted_Probability'])\n",
    "print(f\"Random Forest Average Precision Score: {rf_average_precision}\")\n",
    "\n",
    "xgb_average_precision = average_precision_score(results_df['Actual'], results_df['XGB_Predicted_Probability'])\n",
    "print(f\"XGBoost Average Precision Score: {xgb_average_precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_new_test_probabilities = xgb_model.predict_proba(df_test)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sample_submission.csv\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "\n",
    "new_lines = []\n",
    "for i, prob in enumerate(xgb_new_test_probabilities):\n",
    "    new_lines.append(f\"{lines[i + 1].strip()}{prob}\\n\") \n",
    "\n",
    "with open(\"results.csv\", \"w\") as file:\n",
    "    file.write(\"ID,fraud_flag\\n\")  \n",
    "    file.writelines(new_lines)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
